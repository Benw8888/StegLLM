{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\requests\\compat.py:11\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchardet\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chardet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrl\u001b[39;00m \u001b[39mimport\u001b[39;00m PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     logging,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     46\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\transformers\\dependency_versions_check.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdependency_versions_table\u001b[39;00m \u001b[39mimport\u001b[39;00m deps\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     20\u001b[0m \u001b[39m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# order specific notes:\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     26\u001b[0m pkgs_to_check_at_runtime \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpython tqdm regex requests packaging filelock numpy tokenizers\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39msplit()\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\transformers\\utils\\__init__.py:30\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdoc\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     24\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     ContextManagers,\n\u001b[0;32m     32\u001b[0m     ExplicitEnum,\n\u001b[0;32m     33\u001b[0m     ModelOutput,\n\u001b[0;32m     34\u001b[0m     PaddingStrategy,\n\u001b[0;32m     35\u001b[0m     TensorType,\n\u001b[0;32m     36\u001b[0m     add_model_info_to_auto_map,\n\u001b[0;32m     37\u001b[0m     cached_property,\n\u001b[0;32m     38\u001b[0m     can_return_loss,\n\u001b[0;32m     39\u001b[0m     expand_dims,\n\u001b[0;32m     40\u001b[0m     find_labels,\n\u001b[0;32m     41\u001b[0m     flatten_dict,\n\u001b[0;32m     42\u001b[0m     is_jax_tensor,\n\u001b[0;32m     43\u001b[0m     is_numpy_array,\n\u001b[0;32m     44\u001b[0m     is_tensor,\n\u001b[0;32m     45\u001b[0m     is_tf_symbolic_tensor,\n\u001b[0;32m     46\u001b[0m     is_tf_tensor,\n\u001b[0;32m     47\u001b[0m     is_torch_device,\n\u001b[0;32m     48\u001b[0m     is_torch_dtype,\n\u001b[0;32m     49\u001b[0m     is_torch_tensor,\n\u001b[0;32m     50\u001b[0m     reshape,\n\u001b[0;32m     51\u001b[0m     squeeze,\n\u001b[0;32m     52\u001b[0m     strtobool,\n\u001b[0;32m     53\u001b[0m     tensor_size,\n\u001b[0;32m     54\u001b[0m     to_numpy,\n\u001b[0;32m     55\u001b[0m     to_py_obj,\n\u001b[0;32m     56\u001b[0m     transpose,\n\u001b[0;32m     57\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     60\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     61\u001b[0m     DISABLE_TELEMETRY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m     try_to_load_from_cache,\n\u001b[0;32m     89\u001b[0m )\n\u001b[0;32m     90\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     91\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[0;32m     92\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m     torch_version,\n\u001b[0;32m    173\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\transformers\\utils\\generic.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, ContextManager, List, Tuple\n\u001b[0;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_flax_available, is_tf_available, is_torch_available, is_torch_fx_proxy\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m is_flax_available():\n\u001b[0;32m     33\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\transformers\\utils\\import_utils.py:32\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[1;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m importlib_metadata\n\u001b[0;32m     36\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\transformers\\utils\\logging.py:35\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     CRITICAL,  \u001b[39m# NOQA\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     DEBUG,  \u001b[39m# NOQA\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     WARNING,  \u001b[39m# NOQA\u001b[39;00m\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional\n\u001b[1;32m---> 35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhf_hub_utils\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m auto \u001b[39mas\u001b[39;00m tqdm_lib\n\u001b[0;32m     39\u001b[0m _lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\huggingface_hub\\utils\\__init__.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_chunk_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m chunk_iterable\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_datetime\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_datetime\n\u001b[1;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     BadRequestError,\n\u001b[0;32m     34\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     35\u001b[0m     GatedRepoError,\n\u001b[0;32m     36\u001b[0m     HfHubHTTPError,\n\u001b[0;32m     37\u001b[0m     LocalEntryNotFoundError,\n\u001b[0;32m     38\u001b[0m     RepositoryNotFoundError,\n\u001b[0;32m     39\u001b[0m     RevisionNotFoundError,\n\u001b[0;32m     40\u001b[0m     hf_raise_for_status,\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_fixes\u001b[39;00m \u001b[39mimport\u001b[39;00m SoftTemporaryDirectory, yaml_dump\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_git_credential\u001b[39;00m \u001b[39mimport\u001b[39;00m list_credential_helpers, set_git_credential, unset_git_credential\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrequests\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPError, Response\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_fixes\u001b[39;00m \u001b[39mimport\u001b[39;00m JSONDecodeError\n\u001b[0;32m      8\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mHfHubHTTPError\u001b[39;00m(HTTPError):\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\requests\\__init__.py:45\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib3\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m RequestsDependencyWarning\n\u001b[0;32m     47\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__ \u001b[39mas\u001b[39;00m charset_normalizer_version\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\requests\\exceptions.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mrequests.exceptions\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m~~~~~~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[39mThis module contains the set of Requests' exceptions.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib3\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m BaseHTTPError\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m CompatJSONDecodeError\n\u001b[0;32m     12\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mRequestException\u001b[39;00m(\u001b[39mIOError\u001b[39;00m):\n\u001b[0;32m     13\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"There was an ambiguous exception that occurred while handling your\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m    request.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\requests\\compat.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchardet\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mchardet\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# -------\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Pythons\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# -------\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[39m# Syntax sugar.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\charset_normalizer\\__init__.py:23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mCharset-Normalizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m detect\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__, VERSION\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\charset_normalizer\\api.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     PathLike \u001b[39m=\u001b[39m Union[\u001b[39mstr\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mos.PathLike[str]\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmd\u001b[39;00m \u001b[39mimport\u001b[39;00m mess_ratio\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m CharsetMatches, CharsetMatch\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwarnings\u001b[39;00m \u001b[39mimport\u001b[39;00m warn\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from trl import PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
    "import wandb\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "from accelerate import Accelerator\n",
    "\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"</s>\"\n",
    "DEFAULT_UNK_TOKEN = \"</s>\"\n",
    "\n",
    "class StegEnv():\n",
    "    def __init__(self, \n",
    "                tokenizer: AutoTokenizer,\n",
    "                batch_size: int = 16,\n",
    "                device: str = 'cpu',\n",
    "            ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.key_length = 1 \n",
    "        self.enc_response_len = 4\n",
    "        self.dec_response_len = max(self.key_length, 4) # must be >= 4 for now because of ppo_train\n",
    "\n",
    "        if self.key_length < self.dec_response_len:\n",
    "            print(\"Warning: key length is less than decoder response length. Reward will only use first [key_length] tokens.\")\n",
    "\n",
    "        self.key_tokens = [' 0', ' 1', ' 2', ' 3', ' 4', ' 5', ' 6', ' 7', ' 8', ' 9']\n",
    "        self.prompts = [\" 0 7 3 8 4\", \"Yesterday I went to \", \"The weather today is \", \"What is your favorite \"]\n",
    "\n",
    "        self.prompts_pt = self.tokenizer(self.prompts, return_tensors='pt', padding=True)['input_ids'].to(self.device)\n",
    "        self.key_tokens_pt = self.tokenizer(self.key_tokens, return_tensors='pt', padding=True)['input_ids'].squeeze().to(self.device)\n",
    "\n",
    "        self.prompt_batch = None\n",
    "        self.key_batch = None\n",
    "\n",
    "        key_buff = \"$key:\"\n",
    "        prompt_buff = \"$prompt:\"\n",
    "\n",
    "        self.key_buff_batch = self.tokenizer(key_buff, return_tensors='pt')['input_ids'].repeat(self.batch_size,1).to(self.device)\n",
    "        self.prompt_buff_batch = self.tokenizer(prompt_buff, return_tensors='pt')['input_ids'].repeat(self.batch_size,1).to(self.device)\n",
    "\n",
    "    def _get_encoder_query(self, key, prompt):\n",
    "        \"\"\"\n",
    "        Generates queries of the form \"$key:[key]$prompt:[prompt]\"\n",
    "        \"\"\"\n",
    "        return torch.cat((self.key_buff_batch, key, self.key_buff_batch), dim=-1)\n",
    "        # return torch.cat((self.key_buff_batch, key, prompt_buff_batch, self.prompt_batch), dim=-1)\n",
    "\n",
    "    def _get_decoder_query(self, prompt, response):\n",
    "        return torch.cat((response, self.key_buff_batch), dim=-1)\n",
    "        # return torch.cat((prompt, response, self.key_buff_batch), dim=-1)\n",
    "    \n",
    "    def _get_obs(self):\n",
    "\n",
    "        return {\n",
    "            \"query\": self.query_batch,\n",
    "            \"prompt\": self.prompt_batch,\n",
    "            \"key\": self.key_batch\n",
    "        }\n",
    "\n",
    "    def reset(self, ):\n",
    "        \n",
    "        prompt_idxs = torch.randint(len(self.prompts_pt), size=(self.batch_size,))\n",
    "        key_idxs = torch.randint(len(self.key_tokens_pt), size=(self.batch_size, self.key_length))\n",
    "\n",
    "        self.prompt_batch = self.prompts_pt[prompt_idxs]\n",
    "        self.key_batch = self.key_tokens_pt[key_idxs]\n",
    "        self.query_batch = self._get_encoder_query(self.key_batch, self.prompt_batch)\n",
    "        \n",
    "        obs = self._get_obs()\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _reward_function(self, encoder_response, decoder_response):\n",
    "\n",
    "        decoder_response = decoder_response[:, :self.key_length] # only use first [key_length] tokens\n",
    "        reward_encoder = reward_decoder = (decoder_response == self.key_batch).sum(dim=-1).float()\n",
    "        return (reward_encoder, reward_decoder)\n",
    "\n",
    "    def step(self, encoder_response, decoder_response):\n",
    "\n",
    "        reward = self._reward_function(encoder_response, decoder_response)\n",
    "        return reward\n",
    "\n",
    "\n",
    "class StegPPOTrainer():\n",
    "    def __init__(self,\n",
    "            config: dict,\n",
    "            model: AutoModel,\n",
    "            model_ref: AutoModel,\n",
    "            tokenizer: AutoTokenizer,\n",
    "        ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.model_ref = model_ref\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        batch_size = config['batch_size']\n",
    "        self.episodes = config['episodes']\n",
    "        self.device = config['device']\n",
    "        self.multi_agent = config['multi_agent']\n",
    "\n",
    "        # initialize environment\n",
    "        self.env = StegEnv(\n",
    "            tokenizer = self.tokenizer,\n",
    "            batch_size=batch_size,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        self.enc_gen_kwargs = {\n",
    "            \"min_length\": -1,\n",
    "            \"top_k\": 0.0,\n",
    "            \"top_p\": 1.0,\n",
    "            \"do_sample\": True,\n",
    "            \"pad_token_id\": self.tokenizer.eos_token_id,\n",
    "            \"max_new_tokens\": self.env.enc_response_len\n",
    "        }\n",
    "\n",
    "        # get tokens to suppress\n",
    "        self.suppress_tokens = [i for i in range(self.tokenizer.vocab_size) if i not in self.env.key_tokens_pt]\n",
    "\n",
    "        self.dec_gen_kwargs = {\n",
    "            **self.enc_gen_kwargs,\n",
    "            \"suppress_tokens\": self.suppress_tokens, \n",
    "            \"max_new_tokens\": self.env.dec_response_len, \n",
    "        }\n",
    "\n",
    "        ppo_config = PPOConfig(\n",
    "            batch_size= batch_size * 2 if multi_agent else batch_size, # double for encoder + decoder responses\n",
    "            learning_rate=config['learning_rate'],\n",
    "            steps=config['steps'],\n",
    "            optimize_cuda_cache=True,\n",
    "            )\n",
    "            \n",
    "        self.ppo_trainer = PPOTrainer(ppo_config, self.model, self.model_ref, self.tokenizer)\n",
    "        \n",
    "    def log_stats(\n",
    "        self,\n",
    "        stats: dict,\n",
    "        rewards: List[torch.FloatTensor],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A function that logs all the training stats. Call it at the end of each epoch.\n",
    "        \"\"\"\n",
    "        logs = {}\n",
    "\n",
    "        # Log stats\n",
    "        if not isinstance(rewards, torch.Tensor):\n",
    "            rewards = torch.tensor(rewards).to(self.device)\n",
    "\n",
    "        logs.update(stats)\n",
    "\n",
    "        # manually cast in fp32 for bf16 torch tensors\n",
    "        for k, v in logs.items():\n",
    "            if isinstance(v, torch.Tensor) and v.dtype == torch.bfloat16:\n",
    "                logs[k] = v.float()\n",
    "\n",
    "        logs[\"env/reward_mean\"] = torch.mean(rewards).cpu().numpy().item()\n",
    "        logs[\"env/reward_std\"] = torch.std(rewards).cpu().numpy().item()\n",
    "        logs[\"env/reward_dist\"] = rewards.cpu().numpy()\n",
    "\n",
    "        wandb.log(logs)\n",
    "\n",
    "    def get_model_responses(self, obs):\n",
    "\n",
    "        encoder_query = obs['query']\n",
    "        encoder_response = self.model.generate(encoder_query, **self.enc_gen_kwargs) # should this be ppo_trainer.generate????\n",
    "        encoder_response = encoder_response[:, -self.enc_gen_kwargs[\"max_new_tokens\"]:]\n",
    "\n",
    "        decoder_query = self.env._get_decoder_query(obs['prompt'], encoder_response)\n",
    "        decoder_response = self.model.generate(decoder_query, **self.dec_gen_kwargs)\n",
    "        decoder_response = decoder_response[:, -self.dec_gen_kwargs[\"max_new_tokens\"]:]\n",
    "\n",
    "        return encoder_query, encoder_response, decoder_query, decoder_response\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        for _ in range(self.episodes):\n",
    "            obs = self.env.reset()\n",
    "            enc_query, enc_response, dec_query, dec_response = self.get_model_responses(obs)\n",
    "            enc_reward, dec_reward = self.env.step(enc_response, dec_response)\n",
    "\n",
    "            print('-----------------------------------------------------------------------')\n",
    "            print('prompt, keys:')\n",
    "            print(self.tokenizer.batch_decode(obs['prompt']))\n",
    "            print(self.tokenizer.batch_decode(obs['key']))\n",
    "            print('\\nencoder:')\n",
    "            print(self.tokenizer.batch_decode(obs['query']))\n",
    "            print(self.tokenizer.batch_decode(enc_response))\n",
    "            print(enc_reward)\n",
    "            print('\\ndecoder:')\n",
    "            print(self.tokenizer.batch_decode(dec_query))\n",
    "            print(self.tokenizer.batch_decode(dec_response))\n",
    "            print(dec_reward)\n",
    "            print()\n",
    "\n",
    "            if self.multi_agent:\n",
    "\n",
    "                query = list(enc_query) + list(dec_query)\n",
    "                response = list(enc_response) + list(dec_response)\n",
    "                reward = list(enc_reward) + list(dec_reward)\n",
    "\n",
    "                stats = self.ppo_trainer.step(query, response, reward)\n",
    "\n",
    "            else:\n",
    "                stats = self.ppo_trainer.step(enc_query, enc_response, enc_reward, dec_query, dec_response, dec_reward)\n",
    "\n",
    "            self.log_stats(stats, dec_reward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Accelerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# device = 0 if torch.cuda.is_available() else 'cpu'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m current_device \u001b[39m=\u001b[39m Accelerator()\u001b[39m.\u001b[39mlocal_process_index\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m, current_device)\n\u001b[0;32m      6\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mgpt2\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m16\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmulti_agent\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     14\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Accelerator' is not defined"
     ]
    }
   ],
   "source": [
    "# device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "current_device = Accelerator().local_process_index\n",
    "\n",
    "print('device', current_device)\n",
    "\n",
    "config = {\n",
    "    'model_name': 'gpt2',\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-6,\n",
    "    'steps': 1000,\n",
    "    'episodes': 1000,\n",
    "    'device': current_device,\n",
    "    'multi_agent': True\n",
    "}\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "if config['multi_agent']:\n",
    "    from trl import PPOTrainer\n",
    "else:\n",
    "    from trl_custom import PPOTrainer\n",
    "\n",
    "# model = AutoModelForCausalLMWithValueHead.from_pretrained('gpt2').to(device)\n",
    "\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    config['model_name'],\n",
    "    load_in_8bit=True,\n",
    "    device_map={\"\": current_device},\n",
    "    # peft_config=lora_config,\n",
    "    # layer_norm_names=[],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# model_ref = AutoModelForCausalLMWithValueHead.from_pretrained('gpt2').to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "# config = AutoConfig.from_pretrained(script_args.model_name)\n",
    "\n",
    "if \"llama\" in config.model_name:\n",
    "    # required for llama\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\n",
    "            \"eos_token\": DEFAULT_EOS_TOKEN,\n",
    "            \"bos_token\": DEFAULT_BOS_TOKEN,\n",
    "            \"unk_token\": DEFAULT_UNK_TOKEN,\n",
    "            \"pad_token\": DEFAULT_PAD_TOKEN,\n",
    "        }\n",
    "    )\n",
    "else:\n",
    "    # required for gpt2\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "wandb.init(project=\"julian-runs\")\n",
    "\n",
    "steg_trainer = StegPPOTrainer(config, model, None, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import trl\n",
    "trl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "prompt, keys:\n",
      "[' 0 7 3 8 4', 'What is your favorite ', 'Yesterday I went to ', ' 0 7 3 8 4', 'What is your favorite ', 'What is your favorite ', 'What is your favorite ', 'What is your favorite ', 'Yesterday I went to ', 'What is your favorite ', 'Yesterday I went to ', 'The weather today is ', ' 0 7 3 8 4', 'What is your favorite ', 'The weather today is ', ' 0 7 3 8 4']\n",
      "[' 6', ' 8', ' 4', ' 3', ' 6', ' 9', ' 1', ' 4', ' 4', ' 1', ' 9', ' 9', ' 9', ' 0', ' 1', ' 2']\n",
      "\n",
      "encoder:\n",
      "['$key: 6$key:', '$key: 8$key:', '$key: 4$key:', '$key: 3$key:', '$key: 6$key:', '$key: 9$key:', '$key: 1$key:', '$key: 4$key:', '$key: 4$key:', '$key: 1$key:', '$key: 9$key:', '$key: 9$key:', '$key: 9$key:', '$key: 0$key:', '$key: 1$key:', '$key: 2$key:']\n",
      "[' 1$key:', ' 8$key:', ' 4$key:', ' missing inserted type\\n', ' 5$key:', ' 200$\\n\\n', ' 2 1 $key', ' Incomplete store Default', ' 5$[margin', ' 2$key:', ' 11ac3d', ' 1$fgcolor', ' V<PIN>', \" 'padir |\", ' 2$keys =', ' \"\" $( nreverse']\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "decoder:\n",
      "[' 1$key:$key:', ' 8$key:$key:', ' 4$key:$key:', ' missing inserted type\\n$key:', ' 5$key:$key:', ' 200$\\n\\n$key:', ' 2 1 $key$key:', ' Incomplete store Default$key:', ' 5$[margin$key:', ' 2$key:$key:', ' 11ac3d$key:', ' 1$fgcolor$key:', ' V<PIN>$key:', \" 'padir |$key:\", ' 2$keys =$key:', ' \"\" $( nreverse$key:']\n",
      "['$key:$', 'leea saying input', 'new S const args', ' array with a u', '* p118{', ' `$key`', '1 = (16', ' not. name been', '3](H)', '$nonce:', ' \\\\xae[_', ' 162.00 \\\\', 'RLD$PORT', 'filepath=$(', ' $value developed $', ' $N $N']\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m steg_trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "Cell \u001b[1;32mIn[2], line 199\u001b[0m, in \u001b[0;36mStegPPOTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    196\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(enc_response) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(dec_response)\n\u001b[0;32m    197\u001b[0m     reward \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(enc_reward) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(dec_reward)\n\u001b[1;32m--> 199\u001b[0m     stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mppo_trainer\u001b[39m.\u001b[39;49mstep(query, response, reward)\n\u001b[0;32m    201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mppo_trainer\u001b[39m.\u001b[39mstep(enc_query, enc_response, enc_reward, dec_query, dec_response, dec_reward)\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\trl\\trainer\\ppo_trainer.py:541\u001b[0m, in \u001b[0;36mPPOTrainer.step\u001b[1;34m(self, queries, responses, scores)\u001b[0m\n\u001b[0;32m    536\u001b[0m             model_inputs \u001b[39m=\u001b[39m {k: batch[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m model_inputs_names}\n\u001b[0;32m    537\u001b[0m             logprobs, logits, vpreds, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatched_forward_pass(\n\u001b[0;32m    538\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, batch[\u001b[39m\"\u001b[39m\u001b[39mqueries\u001b[39m\u001b[39m\"\u001b[39m], batch[\u001b[39m\"\u001b[39m\u001b[39mresponses\u001b[39m\u001b[39m\"\u001b[39m], model_inputs\n\u001b[0;32m    539\u001b[0m             )\n\u001b[1;32m--> 541\u001b[0m         train_stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_minibatch(\n\u001b[0;32m    542\u001b[0m             batch[\u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    543\u001b[0m             batch[\u001b[39m\"\u001b[39;49m\u001b[39mvalues\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    544\u001b[0m             batch[\u001b[39m\"\u001b[39;49m\u001b[39mrewards\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    545\u001b[0m             logprobs,\n\u001b[0;32m    546\u001b[0m             logits,\n\u001b[0;32m    547\u001b[0m             vpreds,\n\u001b[0;32m    548\u001b[0m             batch[\u001b[39m\"\u001b[39;49m\u001b[39mmasks\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    549\u001b[0m         )\n\u001b[0;32m    550\u001b[0m         all_stats\u001b[39m.\u001b[39mappend(train_stats)\n\u001b[0;32m    552\u001b[0m timing[\u001b[39m\"\u001b[39m\u001b[39mtime/ppo/optimize_step\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\trl\\trainer\\ppo_trainer.py:760\u001b[0m, in \u001b[0;36mPPOTrainer.train_minibatch\u001b[1;34m(self, old_logprobs, values, rewards, logprobs, logits, vpreds, mask)\u001b[0m\n\u001b[0;32m    755\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(\n\u001b[0;32m    756\u001b[0m         \u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m p: p\u001b[39m.\u001b[39mrequires_grad, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mparameters()), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_grad_norm\n\u001b[0;32m    757\u001b[0m     )\n\u001b[0;32m    759\u001b[0m t \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 760\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    761\u001b[0m train_stats[\u001b[39m\"\u001b[39m\u001b[39mtime/ppo/optimizer_step\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t])\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_device)\n\u001b[0;32m    762\u001b[0m \u001b[39mreturn\u001b[39;00m train_stats\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\accelerate\\optimizer.py:140\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_overflow \u001b[39m=\u001b[39m scale_after \u001b[39m<\u001b[39m scale_before\n\u001b[0;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep(closure)\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[0;32m    144\u001b[0m         exp_avgs,\n\u001b[0;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    147\u001b[0m         state_steps,\n\u001b[0;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m func(params,\n\u001b[0;32m    282\u001b[0m      grads,\n\u001b[0;32m    283\u001b[0m      exp_avgs,\n\u001b[0;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    286\u001b[0m      state_steps,\n\u001b[0;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[1;32mc:\\Users\\yocum\\anaconda3\\envs\\trl\\lib\\site-packages\\torch\\optim\\adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    393\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steg_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2039449755.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    $ pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
